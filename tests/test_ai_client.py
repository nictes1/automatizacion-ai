"""
Test con Cliente AI - Simula un usuario real conversando con el orchestrator
"""

import asyncio
import httpx
from uuid import uuid4
from datetime import datetime, timedelta
import json

# ConfiguraciÃ³n
ORCHESTRATOR_URL = "http://localhost:8005"
OLLAMA_URL = "http://localhost:11434"
WORKSPACE_ID = "550e8400-e29b-41d4-a716-446655440000"

class AIClient:
    """Cliente AI que simula un usuario real"""

    def __init__(self):
        self.client = httpx.AsyncClient(timeout=30.0)
        self.conversation_history = []

    async def generate_user_response(self, assistant_message: str, context: dict) -> str:
        """Genera respuesta del usuario usando LLM"""

        # Construir historial para contexto
        history_text = "\n".join([
            f"{'Usuario' if msg['role'] == 'user' else 'Asistente'}: {msg['content']}"
            for msg in self.conversation_history[-3:]  # Ãšltimos 3 mensajes
        ])

        prompt = f"""Eres un cliente que quiere agendar un turno en una peluquerÃ­a por WhatsApp.

Tu informaciÃ³n personal:
- Nombre: {context['client_name']}
- Email: {context['client_email']}
- Quieres: {context['service']}
- CuÃ¡ndo: {context['when_human']}

Historial de conversaciÃ³n:
{history_text}

El asistente acaba de decirte: "{assistant_message}"

Reglas para tu respuesta:
1. Responde de forma NATURAL y BREVE (como en WhatsApp)
2. Si te piden informaciÃ³n que tienes arriba, dÃ¡sela
3. Si te preguntan por confirmaciÃ³n y ya diste toda la info, confirma
4. Usa un tono casual argentino/rioplatense ("dale", "genial", "sÃ­")
5. NO inventes informaciÃ³n que no estÃ¡ arriba
6. Si el asistente te saluda por primera vez, NO DES TODA TU INFO de golpe, solo tu intenciÃ³n inicial

Devuelve SOLO tu respuesta de usuario (sin "Usuario:" ni prefijos):"""

        response = await self.client.post(
            f"{OLLAMA_URL}/api/chat",
            json={
                "model": "llama3.1:8b",
                "messages": [
                    {"role": "system", "content": "Eres un usuario natural de WhatsApp respondiendo a un asistente."},
                    {"role": "user", "content": prompt}
                ],
                "stream": False,
                "options": {"temperature": 0.7}
            }
        )

        result = response.json()
        user_message = result.get("message", {}).get("content", "").strip()

        # Limpiar respuesta si tiene prefijos
        if user_message.startswith("Usuario:"):
            user_message = user_message.replace("Usuario:", "").strip()

        return user_message

    async def send_to_orchestrator(self, conversation_id: str, user_input: str, current_state: dict = None):
        """EnvÃ­a mensaje al orchestrator"""
        request_data = {
            "conversation_id": conversation_id,
            "user_input": user_input,
            "vertical": "servicios",
            "platform": "whatsapp",
            "current_state": current_state or {}
        }

        response = await self.client.post(
            f"{ORCHESTRATOR_URL}/orchestrator/decide",
            json=request_data,
            headers={"X-Workspace-Id": WORKSPACE_ID}
        )

        return response.json()

    async def close(self):
        await self.client.aclose()


async def simulate_conversation():
    """Simula una conversaciÃ³n completa AI vs AI"""

    ai_client = AIClient()
    conversation_id = str(uuid4())
    tomorrow = (datetime.now() + timedelta(days=1)).strftime("%Y-%m-%d")

    # Contexto del cliente AI
    client_context = {
        "client_name": "Ana GarcÃ­a",
        "client_email": "ana.garcia@gmail.com",
        "service": "Corte y brushing",
        "when_human": "maÃ±ana a las 4 de la tarde",
        "when_date": tomorrow,
        "when_time": "16:00"
    }

    print("="*70)
    print("ğŸ¤– SIMULACIÃ“N: Cliente AI vs Orchestrator")
    print("="*70)
    print(f"ğŸ“± Conversation ID: {conversation_id}")
    print(f"ğŸ‘¤ Cliente: {client_context['client_name']}")
    print(f"ğŸ¯ Objetivo: Agendar {client_context['service']} {client_context['when_human']}")
    print("="*70)

    # Estado inicial
    current_state = {}

    # Turno 1: Cliente inicia la conversaciÃ³n
    print("\n" + "â”€"*70)
    initial_message = f"Hola, necesito {client_context['service'].lower()} {client_context['when_human']}"
    print(f"ğŸ‘¤ Usuario: {initial_message}")
    print("â”€"*70)

    ai_client.conversation_history.append({
        "role": "user",
        "content": initial_message
    })

    response = await ai_client.send_to_orchestrator(conversation_id, initial_message, current_state)

    assistant_message = response.get('assistant', '')
    print(f"ğŸ¤– Asistente: {assistant_message}")
    print(f"ğŸ“Š Slots: {response.get('slots', {})}")
    print(f"ğŸ¯ Next Action: {response.get('next_action')}")

    ai_client.conversation_history.append({
        "role": "assistant",
        "content": assistant_message
    })

    current_state = {
        "greeted": True,
        "slots": response.get('slots', {}),
        "objective": response.get('objective', ''),
        "last_action": response.get('next_action'),
        "attempts_count": 0
    }

    # Continuar conversaciÃ³n hasta completar o mÃ¡ximo 10 turnos
    max_turns = 10
    for turn in range(2, max_turns + 1):
        # Si ya terminÃ³, salir
        if response.get('end') or response.get('next_action') == 'EXECUTE_ACTION':
            print("\n" + "â”€"*70)
            print("âœ… ConversaciÃ³n completada - listos para ejecutar acciÃ³n")
            break

        if response.get('next_action') == 'ASK_HUMAN':
            print("\n" + "â”€"*70)
            print("âš ï¸ Sistema necesita intervenciÃ³n humana")
            break

        # Cliente AI genera respuesta
        user_message = await ai_client.generate_user_response(assistant_message, client_context)

        print("\n" + "â”€"*70)
        print(f"ğŸ‘¤ Usuario: {user_message}")
        print("â”€"*70)

        ai_client.conversation_history.append({
            "role": "user",
            "content": user_message
        })

        # Enviar al orchestrator
        response = await ai_client.send_to_orchestrator(conversation_id, user_message, current_state)

        assistant_message = response.get('assistant', '')
        print(f"ğŸ¤– Asistente: {assistant_message}")
        print(f"ğŸ“Š Slots: {response.get('slots', {})}")
        print(f"ğŸ¯ Next Action: {response.get('next_action')}")

        ai_client.conversation_history.append({
            "role": "assistant",
            "content": assistant_message
        })

        # Actualizar estado
        current_state = {
            "greeted": True,
            "slots": response.get('slots', {}),
            "objective": response.get('objective', ''),
            "last_action": response.get('next_action'),
            "attempts_count": 0
        }

    # Resumen final
    print("\n" + "="*70)
    print("ğŸ“Š RESUMEN FINAL")
    print("="*70)
    print(f"Turnos de conversaciÃ³n: {len(ai_client.conversation_history) // 2}")
    print(f"Slots recolectados: {json.dumps(current_state.get('slots', {}), ensure_ascii=False, indent=2)}")

    if response.get('next_action') == 'EXECUTE_ACTION':
        print("\nğŸ‰ Â¡Ã‰XITO! Todos los datos recolectados, listo para agendar turno")
    elif response.get('next_action') == 'ASK_HUMAN':
        print("\nâš ï¸ El sistema necesitÃ³ derivar a un humano")
    else:
        print(f"\nâš ï¸ ConversaciÃ³n no completada. Ãšltimo estado: {response.get('next_action')}")

    print("="*70)

    await ai_client.close()


if __name__ == "__main__":
    try:
        asyncio.run(simulate_conversation())
    except KeyboardInterrupt:
        print("\n\nâš ï¸ SimulaciÃ³n interrumpida por el usuario")
    except Exception as e:
        print(f"\nâŒ ERROR: {e}")
        import traceback
        traceback.print_exc()
