# ðŸ”„ Flujo Real con n8n - IntegraciÃ³n SLM Pipeline

DocumentaciÃ³n del flujo actual con n8n y cÃ³mo integrar el SLM Pipeline.

---

## ðŸ“Š Arquitectura Actual

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TWILIO (WhatsApp)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            n8n WORKFLOW                           â”‚
â”‚                                                                   â”‚
â”‚  1ï¸âƒ£  Webhook Inbound                                             â”‚
â”‚     â€¢ Recibe POST de Twilio                                      â”‚
â”‚     â€¢ Form data: From, To, Body, MessageSid, etc.               â”‚
â”‚                                                                   â”‚
â”‚  2ï¸âƒ£  Normalize Input                                             â”‚
â”‚     â€¢ Extrae: user_phone, text, wamid, to_phone                 â”‚
â”‚     â€¢ Limpia y normaliza nÃºmeros                                 â”‚
â”‚                                                                   â”‚
â”‚  3ï¸âƒ£  Resolve Channel                                             â”‚
â”‚     â€¢ DB query: workspace_id por to_phone                        â”‚
â”‚     â€¢ Obtiene display_phone, business_name                       â”‚
â”‚                                                                   â”‚
â”‚  4ï¸âƒ£  Load Conversation State                                     â”‚
â”‚     â€¢ DB query: estado conversaciÃ³n                              â”‚
â”‚     â€¢ Parsea: greeted, slots, objective, last_action            â”‚
â”‚                                                                   â”‚
â”‚  5ï¸âƒ£  Prepare Orchestrator Payload                                â”‚
â”‚     â€¢ Arma JSON con todos los datos                              â”‚
â”‚     â€¢ conversation_id, vertical, user_input, slots, etc.        â”‚
â”‚                                                                   â”‚
â”‚  6ï¸âƒ£  Call Orchestrator (HTTP POST)                               â”‚
â”‚     â€¢ POST http://orchestrator:8000/orchestrator/decide         â”‚
â”‚     â€¢ Header: X-Workspace-Id                                     â”‚
â”‚     â€¢ Body: payload preparado                                    â”‚
â”‚                                                                   â”‚
â”‚  7ï¸âƒ£  Parse Intent                                                â”‚
â”‚     â€¢ Lee response.next_action                                   â”‚
â”‚     â€¢ Decide si hay tool_calls                                   â”‚
â”‚                                                                   â”‚
â”‚  8ï¸âƒ£  Execute Action (si hay tool_calls)                          â”‚
â”‚     â€¢ Loop por cada tool_call                                    â”‚
â”‚     â€¢ Ejecuta: book_appointment, get_services, etc.             â”‚
â”‚     â€¢ Persist en DB                                              â”‚
â”‚                                                                   â”‚
â”‚  9ï¸âƒ£  Prepare Response                                            â”‚
â”‚     â€¢ Extrae response.assistant                                  â”‚
â”‚     â€¢ Formatea para Twilio                                       â”‚
â”‚                                                                   â”‚
â”‚  ðŸ”Ÿ Send Twilio                                                  â”‚
â”‚     â€¢ POST a Twilio API                                          â”‚
â”‚     â€¢ To: user_phone, From: display_phone, Body: message        â”‚
â”‚                                                                   â”‚
â”‚  1ï¸âƒ£1ï¸âƒ£ Persist Response                                          â”‚
â”‚     â€¢ Guarda mensaje en DB                                       â”‚
â”‚     â€¢ Actualiza estado de conversaciÃ³n                           â”‚
â”‚                                                                   â”‚
â”‚  1ï¸âƒ£2ï¸âƒ£ Final Response                                            â”‚
â”‚     â€¢ Responde 200 OK a Twilio                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ORCHESTRATOR SERVICE                            â”‚
â”‚                  (FastAPI /orchestrator/decide)                   â”‚
â”‚                                                                   â”‚
â”‚  Actualmente usa: orchestrator_service.py (Legacy)               â”‚
â”‚                                                                   â”‚
â”‚  Con SLM Pipeline:                                                â”‚
â”‚  â”œâ”€ Feature flag: ENABLE_SLM_PIPELINE                            â”‚
â”‚  â”œâ”€ Canary: SLM_CANARY_PERCENT                                   â”‚
â”‚  â”œâ”€ Routing: SLM vs Legacy                                       â”‚
â”‚  â””â”€ Response compatible con n8n                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”Œ IntegraciÃ³n SLM Pipeline

### Cambios MÃ­nimos Necesarios

El SLM Pipeline se integra **sin cambiar n8n**. Solo modificamos el endpoint `/orchestrator/decide`:

#### 1. Endpoint actual (api/orchestrator.py)

```python
@router.post("/decide")
async def decide(request: DecideRequest, x_workspace_id: str = Header(None)):
    """
    n8n llama a este endpoint con:
    {
      "conversation_id": "conv-123",
      "vertical": "servicios",
      "user_input": "Quiero turno maÃ±ana 15hs",
      "greeted": true,
      "slots": {"service_type": "Corte"},
      "objective": "book",
      "last_action": "gather_info"
    }
    """
    
    # Crear snapshot
    snapshot = ConversationSnapshot(
        conversation_id=request.conversation_id,
        vertical=request.vertical,
        user_input=request.user_input,
        workspace_id=x_workspace_id,
        greeted=request.greeted,
        slots=request.slots,
        objective=request.objective
    )
    
    # ANTES: Legacy orchestrator
    # response = await orchestrator_service.decide(snapshot)
    
    # AHORA: SLM Pipeline con canary
    if ENABLE_SLM_PIPELINE:
        response = await orchestrator_slm_pipeline.decide(snapshot)
    else:
        response = await orchestrator_service.decide(snapshot)
    
    # Response para n8n (sin cambios en formato)
    return DecideResponse(
        assistant=response.assistant,
        next_action=response.next_action.value,
        tool_calls=response.tool_calls,
        slots=response.slots,
        objective=request.objective,
        end=response.end
    )
```

#### 2. AdaptaciÃ³n del Snapshot

El `ConversationSnapshot` que usa el SLM Pipeline necesita algunos campos adicionales que n8n no provee. Los completamos en el endpoint:

```python
# En api/orchestrator.py

# Crear snapshot para SLM Pipeline
from services.tool_manifest import load_tool_manifest
from services.mcp_client import get_mcp_client

snapshot_slm = ConversationSnapshot(
    workspace_id=x_workspace_id,
    conversation_id=request.conversation_id,
    user_message=UserMessage(
        text=request.user_input,
        message_id=f"n8n-{x_request_id}"
    ),
    business_name=await _load_business_name(x_workspace_id),
    tool_manifest=await load_tool_manifest(x_workspace_id, request.vertical),
    mcp_client=await get_mcp_client(x_workspace_id),
    custom_runners={},
    vertical=request.vertical,
    slots=request.slots,
    greeted=request.greeted,
    objective=request.objective
)
```

---

## ðŸ“ Contratos JSON

### Request de n8n â†’ Orchestrator

```json
{
  "conversation_id": "conv-550e8400-e29b-41d4-a716-446655440003",
  "vertical": "servicios",
  "user_input": "Quiero reservar un corte de pelo maÃ±ana a las 3pm",
  "greeted": true,
  "slots": {
    "service_type": "Corte de Cabello",
    "preferred_date": "2025-10-16"
  },
  "objective": "book",
  "last_action": "gather_date",
  "attempts_count": 1
}
```

### Response Orchestrator â†’ n8n

```json
{
  "assistant": "Â¿Te viene bien a las 15:00? Necesito tu nombre y email para confirmar.",
  "next_action": "gather_client_info",
  "tool_calls": [
    {
      "tool": "check_service_availability",
      "args": {
        "workspace_id": "550e8400-e29b-41d4-a716-446655440003",
        "service_type": "Corte de Cabello",
        "date": "2025-10-16"
      }
    }
  ],
  "slots": {
    "service_type": "Corte de Cabello",
    "preferred_date": "2025-10-16",
    "preferred_time": "15:00"
  },
  "objective": "book",
  "end": false,
  "debug": {
    "route": "slm_pipeline",
    "intent": "book",
    "confidence": 0.92,
    "t_total_ms": 850
  }
}
```

---

## ðŸš€ Plan de IntegraciÃ³n

### Fase 1: PreparaciÃ³n (1 dÃ­a)

**1. Actualizar api/orchestrator.py**
- âœ… Agregar imports de `OrchestratorServiceIntegrated`
- âœ… Agregar feature flags (`ENABLE_SLM_PIPELINE`, `SLM_CANARY_PERCENT`)
- âœ… Agregar field `debug` a `DecideResponse`
- âœ… Documentar flujo con n8n

**2. Crear adapter en api/orchestrator.py**
```python
async def _create_slm_snapshot(
    request: DecideRequest,
    x_workspace_id: str
) -> ConversationSnapshot:
    """
    Convierte DecideRequest (de n8n) a ConversationSnapshot (para SLM Pipeline)
    """
    # Cargar dependencias
    manifest = await load_tool_manifest(x_workspace_id, request.vertical)
    mcp_client = await get_mcp_client(x_workspace_id)
    business_name = await _load_business_name(x_workspace_id)
    
    return ConversationSnapshot(
        workspace_id=x_workspace_id,
        conversation_id=request.conversation_id,
        user_message=UserMessage(
            text=request.user_input,
            message_id=f"n8n-{uuid.uuid4()}"
        ),
        business_name=business_name,
        tool_manifest=manifest,
        mcp_client=mcp_client,
        custom_runners={},
        vertical=request.vertical,
        slots=request.slots,
        greeted=request.greeted,
        objective=request.objective
    )
```

**3. Inicializar orchestrator SLM en startup**
```python
# En services/orchestrator_app.py o main.py

from services.orchestrator_integration import OrchestratorServiceIntegrated
from services.llm_client import get_llm_client

# Startup event
@app.on_event("startup")
async def startup():
    llm_client = get_llm_client()
    
    app.state.orchestrator_slm = OrchestratorServiceIntegrated(
        llm_json_client=llm_client,
        enable_agent_loop=True
    )
    
    logger.info(f"Orchestrator SLM initialized: enabled={app.state.orchestrator_slm.enable_slm_pipeline}")
```

### Fase 2: Testing Local (1 dÃ­a)

**1. Test unitario del adapter**
```bash
pytest tests/unit/test_orchestrator_n8n_adapter.py -v
```

**2. Test E2E simulando n8n**
```python
# tests/e2e/test_orchestrator_n8n_flow.py

async def test_n8n_to_orchestrator_flow():
    """Simula request de n8n â†’ orchestrator SLM â†’ response"""
    
    # Request simulado de n8n
    request = DecideRequest(
        conversation_id="conv-test-123",
        vertical="servicios",
        user_input="Quiero turno maÃ±ana 15hs",
        greeted=True,
        slots={"service_type": "Corte"},
        objective="book"
    )
    
    # Call endpoint
    response = await client.post(
        "/orchestrator/decide",
        json=request.dict(),
        headers={"X-Workspace-Id": "ws-test-123"}
    )
    
    # Validar response
    assert response.status_code == 200
    data = response.json()
    assert "assistant" in data
    assert "tool_calls" in data
    assert "slots" in data
    assert data["debug"]["route"] in ["slm_pipeline", "legacy"]
```

### Fase 3: Staging (2 dÃ­as)

**1. Deploy a staging**
```bash
# Configurar
export ENABLE_SLM_PIPELINE=true
export SLM_CANARY_PERCENT=0  # 100% SLM en staging

# Deploy
docker-compose -f docker-compose.staging.yml up -d orchestrator
```

**2. Validar con n8n staging**
- Enviar mensaje WhatsApp a nÃºmero de staging
- Ver logs de n8n: webhook â†’ orchestrator â†’ response
- Ver logs de orchestrator: SLM pipeline execution
- Verificar respuesta recibida en WhatsApp

**3. MÃ©tricas**
```bash
# Ver telemetrÃ­a
tail -f logs/orchestrator.log | grep TELEMETRY

# Latencias
grep "t_total_ms" logs/orchestrator.log | awk '{print $NF}' | sort -n

# Route distribution
grep "route=" logs/orchestrator.log | awk -F'route=' '{print $2}' | awk '{print $1}' | sort | uniq -c
```

### Fase 4: Canary 10% (3-5 dÃ­as)

**1. Deploy canary**
```bash
export ENABLE_SLM_PIPELINE=true
export SLM_CANARY_PERCENT=10  # 10% SLM, 90% Legacy

docker-compose -f docker-compose.prod.yml up -d orchestrator
```

**2. Monitoreo**
- Dashboard Grafana con mÃ©tricas por route
- Alertas si latencia > p90 o error rate > 2%
- Comparar SLM vs Legacy (accuracy, latencia, UX)

**3. Criterios de Ã©xito**
- âœ… p90 latency < 1500ms
- âœ… Error rate < 1%
- âœ… No quejas de usuarios
- âœ… Tool execution rate similar o mejor que legacy

### Fase 5: Full Rollout (1 semana)

**1. Escalar gradualmente**
```bash
# DÃ­a 1-2: 10%
export SLM_CANARY_PERCENT=10

# DÃ­a 3-4: 50%
export SLM_CANARY_PERCENT=50

# DÃ­a 5+: 100%
export SLM_CANARY_PERCENT=0  # 0 = 100% SLM
```

**2. Monitoreo continuo**
- MÃ©tricas diarias
- Feedback de usuarios
- Ajustes de prompts si es necesario

---

## ðŸ”§ Troubleshooting

### Problema: "No workspace found"

**SÃ­ntoma:**
```
ERROR [WEBHOOK] No workspace found for from=whatsapp:+5491112345678
```

**Causa:** n8n no pudo resolver workspace_id desde to_phone

**SoluciÃ³n:**
```sql
-- Verificar mapping en DB
SELECT workspace_id, display_phone FROM pulpo.channels WHERE display_phone = '+14155238886';
```

### Problema: "Tool manifest not loaded"

**SÃ­ntoma:**
```
ERROR [ORCHESTRATOR] tool_manifest is None
```

**Causa:** No se cargÃ³ el manifest para el workspace

**SoluciÃ³n:**
```python
# Verificar carga de manifest
manifest = await load_tool_manifest(workspace_id, "servicios")
assert manifest is not None
assert len(manifest.tools) > 0
```

### Problema: "Response format incompatible"

**SÃ­ntoma:**
n8n falla al parsear response del orchestrator

**Causa:** Campo faltante o tipo incorrecto en DecideResponse

**SoluciÃ³n:**
```python
# Asegurar todos los campos requeridos
return DecideResponse(
    assistant=response.assistant or "Error",
    next_action=response.next_action.value if hasattr(response.next_action, 'value') else "answer",
    tool_calls=response.tool_calls or [],
    slots=response.slots or {},
    objective=request.objective,
    end=response.end or False
)
```

---

## ðŸ“š Referencias

- **n8n workflow**: `n8n/n8n-workflow.json`
- **Orchestrator API**: `api/orchestrator.py`
- **SLM Pipeline**: `services/orchestrator_slm_pipeline.py`
- **Integration**: `services/orchestrator_integration.py`

---

**Ãšltima actualizaciÃ³n:** 16 Enero 2025  
**Estado:** âœ… DOCUMENTADO - LISTO PARA INTEGRACIÃ“N




