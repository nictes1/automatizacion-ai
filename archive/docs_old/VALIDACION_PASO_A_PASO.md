# ğŸ§ª ValidaciÃ³n Paso a Paso - IntegraciÃ³n n8n

GuÃ­a para validar la integraciÃ³n de forma incremental.

---

## ğŸ“‹ Estrategia de ValidaciÃ³n

**Paso 1**: Validar contrato n8n con Legacy 100% (aislar variables)  
**Paso 2**: Activar SLM Pipeline canary 10% (validar integraciÃ³n)  
**Paso 3**: Escalar gradualmente (50% â†’ 100%)

---

## ğŸ”¹ PASO 1: Validar Legacy (Contrato n8n)

### Objetivo
Verificar que el nuevo formato de API funciona perfectamente con Legacy, **antes** de introducir SLM Pipeline.

### Config

```bash
export ENABLE_SLM_PIPELINE=false
export SLM_CANARY_PERCENT=0
```

### Tests Manuales

**1. Saludo**
```bash
curl -s -X POST "http://localhost:8000/orchestrator/decide" \
  -H "Content-Type: application/json" \
  -H "X-Workspace-Id: 550e8400-e29b-41d4-a716-446655440003" \
  -H "X-Channel: whatsapp" \
  -H "X-Conversation-Id: wa-5492235261872" \
  -H "X-Request-Id: 2025-01-16T10:00:00Z-SM001" \
  -d @tests/fixtures/request_saludo.json | jq
```

**Validar:**
- âœ… `assistant.text` presente (< 200 chars)
- âœ… `tool_calls` es array (vacÃ­o o con tools)
- âœ… `patch.slots` existe (dict)
- âœ… `telemetry.route` = "legacy"
- âœ… `telemetry.total_ms` < 2000

**2. Consulta precio**
```bash
curl -s -X POST "http://localhost:8000/orchestrator/decide" \
  -H "Content-Type: application/json" \
  -H "X-Workspace-Id: 550e8400-e29b-41d4-a716-446655440003" \
  -H "X-Channel: whatsapp" \
  -H "X-Conversation-Id: wa-5492235261872" \
  -H "X-Request-Id: 2025-01-16T10:01:00Z-SM002" \
  -d @tests/fixtures/request_precio.json | jq
```

**Validar:**
- âœ… `assistant.text` menciona precio
- âœ… `tool_calls` puede contener `get_available_services`
- âœ… Response < 2s

**3. Reserva**
```bash
curl -s -X POST "http://localhost:8000/orchestrator/decide" \
  -H "Content-Type: application/json" \
  -H "X-Workspace-Id: 550e8400-e29b-41d4-a716-446655440003" \
  -H "X-Channel: whatsapp" \
  -H "X-Conversation-Id: wa-5492235261872" \
  -H "X-Request-Id: 2025-01-16T10:02:00Z-SM003" \
  -d @tests/fixtures/request_reserva.json | jq
```

**Validar:**
- âœ… `assistant.text` pide dato faltante (nombre/email/servicio)
- âœ… `patch.slots` contiene slots extraÃ­dos
- âœ… `tool_calls` puede estar vacÃ­o (si faltan datos)

### Tests Automatizados

```bash
# Con Legacy forzado
export ENABLE_SLM_PIPELINE=false
./tests/smoke/test_n8n_contract.sh
```

**Criterios de Ã©xito:**
- âœ… 100% tests passing
- âœ… Latencia p90 < 1500ms
- âœ… Sin errores 500
- âœ… Response format compatible con n8n

### Checklist Paso 1

- [ ] Tests manuales (saludo, precio, reserva) funcionan
- [ ] Tests automatizados pasan
- [ ] Formato de response es exacto (n8n lo puede parsear)
- [ ] Logs muestran `route=legacy`
- [ ] No hay errores en logs

---

## ğŸ”¹ PASO 2: SLM Pipeline Canary 10%

### Objetivo
Activar SLM Pipeline para 10% del trÃ¡fico y validar que funciona igual o mejor que Legacy.

### Config

```bash
export ENABLE_SLM_PIPELINE=true
export SLM_CANARY_PERCENT=10  # 10% SLM, 90% Legacy
```

### ImplementaciÃ³n Previa

**1. Implementar `_decide_with_slm_pipeline()` en api/orchestrator.py:**

Ver cÃ³digo completo en siguiente secciÃ³n.

**2. Inicializar singletons en startup:**

```python
# En services/orchestrator_app.py o main.py

from services.orchestrator_integration import OrchestratorServiceIntegrated
from services.llm_client import get_llm_client

@app.on_event("startup")
async def startup():
    # LLM client
    llm_client = get_llm_client()
    
    # SLM Pipeline
    app.state.orchestrator_slm = OrchestratorServiceIntegrated(
        llm_json_client=llm_client,
        enable_agent_loop=True
    )
    
    logger.info(f"SLM Pipeline initialized: enabled={app.state.orchestrator_slm.enable_slm_pipeline}")
```

### Tests con Canary

**Ejecutar mÃºltiples requests:**

```bash
# Ejecutar 20 requests â†’ ~2 deberÃ­an ir a SLM
for i in {1..20}; do
  curl -s -X POST "http://localhost:8000/orchestrator/decide" \
    -H "Content-Type: application/json" \
    -H "X-Workspace-Id: 550e8400-e29b-41d4-a716-446655440003" \
    -H "X-Channel: whatsapp" \
    -H "X-Conversation-Id: wa-test-$i" \
    -H "X-Request-Id: 2025-01-16T10:00:$i-SM$i" \
    -d @tests/fixtures/request_saludo.json \
    | jq -r '.telemetry.route'
done | sort | uniq -c
```

**Output esperado:**
```
     18 legacy
      2 slm_pipeline
```

### MÃ©tricas a Observar

**En logs:**
```bash
# DistribuciÃ³n de routes
grep "ROUTING" logs/orchestrator.log | awk '{print $2}' | sort | uniq -c

# Latencias
grep "total_ms" logs/orchestrator.log | jq .telemetry.total_ms | sort -n

# Errores
grep "ERROR" logs/orchestrator.log | wc -l
```

**MÃ©tricas clave:**
- âœ… `slm_pipeline` aparece ~10% del tiempo
- âœ… p90 latency SLM < 1500ms
- âœ… Error rate SLM < 1%
- âœ… Respuestas SLM igual de buenas que Legacy

### Checklist Paso 2

- [ ] `_decide_with_slm_pipeline()` implementado
- [ ] Singletons inicializados en startup
- [ ] Canary 10% activo
- [ ] Logs muestran mix de `route=slm_pipeline` y `route=legacy`
- [ ] Latencia SLM similar o mejor que Legacy
- [ ] Sin errores en SLM Pipeline
- [ ] n8n procesa respuestas de ambos routes sin problemas

---

## ğŸ”¹ PASO 3: Escalar Gradualmente

### Fase 1: Canary 50% (DÃ­a 1-2)

```bash
export SLM_CANARY_PERCENT=50
systemctl restart orchestrator  # o docker-compose restart
```

**Validar:**
- DistribuciÃ³n 50/50 en logs
- Comparar mÃ©tricas SLM vs Legacy
- Identificar edge cases donde SLM falla

### Fase 2: Full SLM (DÃ­a 3+)

```bash
export SLM_CANARY_PERCENT=0  # 0 = 100% SLM
systemctl restart orchestrator
```

**Validar:**
- 100% trÃ¡fico a SLM
- Legacy solo como fallback (en caso de error)
- Monitorear 48hs continuas

### Fase 3: Deprecar Legacy (Semana 2+)

Una vez que SLM estÃ© estable:
- Mantener Legacy solo para rollback
- Documentar lecciones aprendidas
- Ajustar prompts basado en feedback

---

## ğŸš¨ Troubleshooting

### Problema: Legacy no responde con nuevo formato

**SÃ­ntoma:**
```json
{
  "detail": "Field required: assistant"
}
```

**Causa:** Adapter Legacy â†’ DecideResponse no funciona

**SoluciÃ³n:**
Verificar `_decide_with_legacy()` en api/orchestrator.py

### Problema: SLM Pipeline falla con 500

**SÃ­ntoma:**
```
HTTPException: SLM pipeline no inicializado
```

**Causa:** Singleton no inicializado en startup

**SoluciÃ³n:**
```python
# En startup event
app.state.orchestrator_slm = OrchestratorServiceIntegrated(llm_client)
```

### Problema: Routing no respeta canary %

**SÃ­ntoma:** Siempre va a Legacy o siempre a SLM

**Causa:** Hash MD5 no funciona

**SoluciÃ³n:**
```python
# Verificar funciÃ³n _decide_route()
bucket = int(hashlib.md5(conversation_id.encode()).hexdigest(), 16) % 100
```

### Problema: n8n no parsea response

**SÃ­ntoma:** n8n workflow falla en "Parse Response"

**Causa:** Campo faltante o tipo incorrecto

**SoluciÃ³n:**
Validar schema con:
```bash
curl ... | jq . > response.json
python -c "
from pydantic import ValidationError
from api.orchestrator import DecideResponse
import json
try:
    DecideResponse(**json.load(open('response.json')))
    print('âœ… Valid')
except ValidationError as e:
    print('âŒ Invalid:', e)
"
```

---

## ğŸ“Š Criterios de Ã‰xito Final

### Paso 1: Legacy âœ…

- [x] Contrato n8n funciona 100%
- [x] Tests pasan
- [x] Latencia < 1500ms p90
- [x] Sin errores

### Paso 2: SLM Canary 10% âœ…

- [ ] Routing funciona (10% SLM, 90% Legacy)
- [ ] Latencia SLM similar a Legacy
- [ ] Sin errores en SLM
- [ ] n8n procesa ambos routes

### Paso 3: Full Rollout âœ…

- [ ] 100% SLM estable
- [ ] MÃ©tricas iguales o mejores que Legacy
- [ ] Sin quejas de usuarios
- [ ] Legacy disponible para rollback

---

## ğŸ“š Referencias

- **CÃ³digo**: `api/orchestrator.py`
- **Contrato**: `CONTRATO_N8N.md`
- **Tests**: `tests/smoke/test_n8n_contract.sh`
- **Fixtures**: `tests/fixtures/*.json`

---

**Ãšltima actualizaciÃ³n:** 16 Enero 2025  
**Estado:** Paso 1 en progreso




